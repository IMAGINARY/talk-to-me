<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Talk to Me</title>
    <link rel="stylesheet" type="text/css" href="../../node_modules/@fortawesome/fontawesome-free/css/all.css">
    <style>
        body {
            background-color: #202020;
            text-align: center;
            color: #F0F0F0;
            font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;
        }

        #record-button {
            font-size: 3em;
        }

        #waveform-viz {
            width: 100%;
        }

        .chunk {
            border: 1px solid gray;
        }

        #mic {
            text-align: center;
            vertical-align: middle;
            border-radius: 40px;
            width: 80px;
            height: 80px;
            background-color: #404040;
            text-align: center;
            margin: 0 auto;
        }

        #main {
            margin: 0 auto;
            text-align: center;
            padding: 20px;
            margin: 20px;
            width: 100%;
        }

        #waveform {
            margin: 20px;
            border-radius: 20px;
            padding: 10px 25px 10px 25px;
            background-color: #FFFF20;
            margin: 0 auto;
            text-align: center;
            width: 60%;
        }

        #lang {
            width: 100%;
            border: none;
            padding: 20px;
            border-collapse: collapse;
        }

        tr {
            border: 0;
        }

        td {
            border: 0;
        }

        th {
            border: 0;
        }
    </style>
    <script>
        const assert = require('assert');
        const fs = require('fs').promises;
        const path = require('path');
        const EventEmitter = require('events');

        const wav2letter = require("../js/common/wav2letter/wav2letter.js");
        Promise.all(['en', 'de'].map(lang => wav2letter.transcribe({waveform: new Float32Array(), lang: lang})))
            .then(() => console.log("Speech recognition models loaded."));

        function addText(text, lang) {
            console.log(lang + ":", text);
            const chunkContainer = document.getElementById(`chunks-${lang}`);
            chunkContainer.appendChild(document.createTextNode(text));
            chunkContainer.appendChild(document.createElement('br'));
        }

        class FixedSizeFloat32Buffer extends EventEmitter {
            constructor(maxLength) {
                super();
                this.buffer = new Float32Array(maxLength);
                this.count = 0;
            }

            push(data) {
                const newData = data.subarray(0, this.buffer.length - this.count);
                const overflow = data.subarray(this.buffer.length - this.count);
                if (newData.length > 0) {
                    this.buffer.set(newData, this.count);
                    const prevCount = this.count;
                    this.count += newData.length;
                    this.emit('data', this.buffer.subarray(prevCount, this.count));
                    if (this.count === this.buffer.length) {
                        this.emit('full', this.buffer);
                    }
                }
                return overflow;
            }

            clear() {
                this.count = 0;
            }

            get data() {
                return this.buffer.subarray(0, this.count);
            }

            get length() {
                return this.count;
            }

            get maxLength() {
                return this.buffer.length;
            }
        }

        async function init() {
            const lengthInMs = 2000;
            const sampleRate = 16000;
            const samples = new FixedSizeFloat32Buffer(lengthInMs * sampleRate / 1000);
            // Initially fill up the buffer
            samples.push(new Float32Array(samples.maxLength));

            const createFilters = context => {
                const filter = context.createBiquadFilter();
                filter.Q.value = 8.30;
                filter.frequency.value = 355;
                filter.gain.value = 3.0;
                filter.type = 'bandpass';

                const compressor = context.createDynamicsCompressor();
                compressor.threshold.value = -50;
                compressor.knee.value = 40;
                compressor.ratio.value = 12;
                compressor.reduction.value = -20;
                compressor.attack.value = 0;
                compressor.release.value = 0.25;

                filter.connect(compressor);

                return [filter, compressor];
            };

            const micStream = await navigator.mediaDevices.getUserMedia({
                audio: {sampleRate: 16000, noiseSuppression: true, autoGainControl: false},
                video: false
            });

            const context = new AudioContext({sampleRate: sampleRate});
            const source = context.createMediaStreamSource(micStream);
            const gain = context.createGain();
            const processor = context.createScriptProcessor(1024, 1, 1);
            processor.onaudioprocess = e => samples.push(e.inputBuffer.getChannelData(0));
            const filters = createFilters(context);

            window.context = context;
            window.micStream = micStream;

            const useFilters = false
            if (useFilters) {
                source.connect(gain);
                gain.connect(filters[0]);
                filters[filters.length - 1].connect(processor);
                filters[filters.length - 1].connect(context.destination);
                processor.connect(context.destination);
            } else {
                source.connect(gain);
                gain.connect(context.destination);
                gain.connect(processor);
                processor.connect(context.destination);
            }

            samples.on('data', () => drawWaveform());

            samples.on('full', async data => {
                await stopRecording();
                const lettersEn = await wav2letter.transcribe({waveform: data, lang: 'en'});
                addText(lettersEn, 'en');
                const lettersDe = await wav2letter.transcribe({waveform: data, lang: 'de'});
                addText(lettersDe, 'de');
            });

            async function startRecording() {
                samples.clear();
                await unmuteRecording();
            }

            async function stopRecording() {
                await muteRecording();
            }

            async function muteRecording() {
                gain.gain.value = 0.0;
            }

            async function unmuteRecording() {
                gain.gain.value = 1.0;
            }

            await stopRecording();

            const canvas = document.querySelector('#waveform-viz');
            const canvasCtx = canvas.getContext("2d");

            function drawWaveform() {
                const amplification = 1.0 / samples.data.reduce((max, cur) => Math.max(max, Math.abs(cur)), 0.1);

                canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

                canvasCtx.save();
                canvasCtx.imageSmoothingEnabled = false;
                canvasCtx.translate(0, canvas.height / 2.0);
                canvasCtx.strokeStyle = '#999';
                canvasCtx.fillStyle = '#000';
                canvasCtx.beginPath();
                canvasCtx.moveTo(0, 0);
                canvasCtx.lineTo(canvas.width * samples.length, 0.0);
                canvasCtx.stroke();
                canvasCtx.strokeStyle = '#000';
                canvasCtx.beginPath();
                canvasCtx.moveTo(0, 0);
                const samplesSoFar = samples.data;
                for (let i = 0; i < samplesSoFar.length; ++i)
                    canvasCtx.lineTo(i / samples.maxLength * canvas.width, +0.5 * amplification * samplesSoFar[i] * canvas.height);
                for (let i = samplesSoFar.length - 1; i >= 0; --i)
                    canvasCtx.lineTo(i / samples.maxLength * canvas.width, -0.5 * amplification * samplesSoFar[i] * canvas.height);
                canvasCtx.closePath();
                canvasCtx.fill();
                canvasCtx.stroke();
                canvasCtx.restore();
            }

            drawWaveform();

            return {
                startRecording: startRecording,
                stopRecording: stopRecording,
                muteRecording: muteRecording,
            };
        }
    </script>
</head>
<body>
<div id="main">
    <div id="waveform">
        <canvas id="waveform-viz" width="512" height="128"></canvas>
    </div>
    <br>
    <br>
    <div id="mic">
        <br>
        <i id="record-button"
           class="fas fa-microphone"
           onmousedown="state.startRecording(); this.style.color='red';"
           onmouseup="state.muteRecording(); this.style.color='inherit';">
        </i>
    </div>
    <form>
        <table border="1" align="center" width="100%" id="lang">
            <tr>
                <th width="50%">English</th>
                <th width="50%">German</th>
                <!--
                <th width="50%"><input type="radio" id="en" name="language" value="English" onchange="state.setLanguage('en');" checked>
                    <label for="en"> English</label></th>
                <th width="50%"><input type="radio" id="de" name="language" value="German" onchange="state.setLanguage('de');">
                    <label for="de"> German</label></th>
                -->
            </tr>
            <tr>
                <td id="chunks-en" valign="top"></td>
                <td id="chunks-de" valign="top"></td>
            </tr>
        </table>
    </form>
</div>
<script>
    let state;
    init().then(s => state = s);
</script>
</body>
</html>
