<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Talk to Me</title>
    <link rel="stylesheet" type="text/css" href="../../node_modules/@fortawesome/fontawesome-free/css/all.css">
    <style>
        body {
            background-color: #202020;
            text-align: center;
            color: #F0F0F0;
            font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;
        }

        #record-button {
            font-size: 3em;
        }

        #waveform-viz {
            width: 100%;
        }

        #spectrogram-viz {
            width: 100%;
        }

        .transcription-wrapper {
            margin-top: 1em;
        }

        .transcription {
            font-family: monospace;
            white-space: pre;
            margin-top: 0.5em;
            height: 5em;
        }

        #mic {
            text-align: center;
            vertical-align: middle;
            border-radius: 40px;
            width: 80px;
            height: 80px;
            background-color: #404040;
            text-align: center;
            margin: 0 auto;
        }

        #main {
            margin: 0 auto;
            text-align: center;
            padding: 20px;
            margin: 20px;
            width: 100%;
        }

        #waveform {
            margin: 20px;
            border-radius: 20px;
            padding: 10px 25px 10px 25px;
            background-color: #FFFF20;
            margin: 0 auto;
            text-align: center;
            width: 60%;
        }

        #lang {
            width: 100%;
            border: none;
            padding: 20px;
            border-collapse: collapse;
        }

        tr {
            border: 0;
        }

        td {
            border: 0;
        }

        th {
            border: 0;
        }
    </style>
    <script>
        const assert = require('assert');
        const fs = require('fs').promises;
        const path = require('path');
        const EventEmitter = require('events');
        const ndarray = require('ndarray');
        const unpack = require('ndarray-unpack');
        const ops = require('ndarray-ops');
        const colormap = require('colormap')

        const wav2letter = require("../js/common/wav2letter/wav2letter.js");
        const w2lUtils = require('../js/common/wav2letter/util.js');

        Promise.all(['en', 'de'].map(lang => wav2letter.transcribe({waveform: new Float32Array(), lang: lang})))
            .then(() => console.log("Speech recognition models loaded."));

        function setTranscriptionText(text, lang) {
            console.log(lang + ":", text);
            const chunkContainer = document.getElementById(`chunks-${lang}`);
            chunkContainer.innerHTML = "";
            chunkContainer.appendChild(document.createTextNode(text));
        }

        function addLettersForPredictionExt(predictionExt) {
            const letterActivations = predictionExt.layers[11];
            const decoded = wav2letter.decoder.decodeGreedyAll(letterActivations);
            const decodedBest4 = decoded.hi(decoded.shape[0], 4);
            const letters = wav2letter.decoder.indexToLetter(decodedBest4, predictionExt.letters);
            const strings = unpack(letters.transpose(1, 0)).map(lineLetters => lineLetters.join(""));
            setTranscriptionText(strings.join("\n"), predictionExt.lang);
        }

        // maps a value between 0 and 1 to RGB color array
        const heatmap = (() => {
            const palette = colormap({
                colormap: 'hot',
                nshades: 256,
                format: 'rgba',
                alpha: 1
            }).reverse();

            // map (0, 1) range for alpha to (0, 255)
            palette.forEach(c => c[3] = c[3] * 255);

            return value => {
                const constrainedValue = value < 0.0 ? 0.0 : (value > 1.0 ? 1.0 : value);
                const index = Math.floor(255 * constrainedValue);
                return palette[index];
            };
        })();

        const alphamap = (() => {
            const palette = Array.from({length: 256}, (_, i) => [0, 0, 0, i]);
            return value => {
                const constrainedValue = value < 0.0 ? 0.0 : (value > 1.0 ? 1.0 : value);
                const index = Math.floor(255 * constrainedValue);
                return palette[index];
            };
        })();

        function drawSpectrogram(logMelSpectrogramData) {
            const tempCanvas = document.createElement("canvas");
            const tempCtx = tempCanvas.getContext("2d");

            const min = ops.inf(logMelSpectrogramData);
            const max = ops.sup(logMelSpectrogramData);
            const range = max - min;

            const imageData = tempCtx.createImageData(logMelSpectrogramData.shape[0], logMelSpectrogramData.shape[1]);
            for (let y = 0; y < imageData.height; ++y) {
                for (let x = 0; x < imageData.width; ++x) {
                    const value = logMelSpectrogramData.get(x, y);
                    const normalizedValue = (value - min) / range;
                    const color = alphamap(normalizedValue);
                    imageData.data[4 * (y * imageData.width + x) + 0] = color[0];
                    imageData.data[4 * (y * imageData.width + x) + 1] = color[1];
                    imageData.data[4 * (y * imageData.width + x) + 2] = color[2];
                    imageData.data[4 * (y * imageData.width + x) + 3] = color[3];
                }
            }
            tempCtx.putImageData(imageData, 0, 0);

            // TODO: avoid creating a new canvas every time
            const canvas = document.getElementById("spectrogram-viz");
            const ctx = canvas.getContext("2d");
            ctx.imageSmoothingEnabled = false;

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            ctx.save();
            const xscale = canvas.width / logMelSpectrogramData.shape[0];
            const yscale = canvas.height / logMelSpectrogramData.shape[1];
            ctx.translate(0, canvas.height);
            ctx.scale(xscale, -yscale);
            ctx.drawImage(tempCanvas, 0, 0);
            ctx.restore();
        }

        class FixedSizeFloat32Buffer extends EventEmitter {
            constructor(maxLength) {
                super();
                this.buffer = new Float32Array(maxLength);
                this.count = 0;
            }

            push(data) {
                const newData = data.subarray(0, this.buffer.length - this.count);
                const overflow = data.subarray(this.buffer.length - this.count);
                if (newData.length > 0) {
                    this.buffer.set(newData, this.count);
                    const prevCount = this.count;
                    this.count += newData.length;
                    this.emit('data', this.buffer.subarray(prevCount, this.count));
                    if (this.count === this.buffer.length) {
                        this.emit('full', this.buffer);
                    }
                }
                return overflow;
            }

            clear() {
                this.count = 0;
            }

            get data() {
                return this.buffer.subarray(0, this.count);
            }

            get length() {
                return this.count;
            }

            get maxLength() {
                return this.buffer.length;
            }
        }

        async function init() {
            const lengthInMs = 2000;
            const sampleRate = 16000;
            const samples = new FixedSizeFloat32Buffer(lengthInMs * sampleRate / 1000);
            // Initially fill up the buffer
            samples.push(new Float32Array(samples.maxLength));

            const createFilters = context => {
                const filter = context.createBiquadFilter();
                filter.Q.value = 8.30;
                filter.frequency.value = 355;
                filter.gain.value = 3.0;
                filter.type = 'bandpass';

                const compressor = context.createDynamicsCompressor();
                compressor.threshold.value = -50;
                compressor.knee.value = 40;
                compressor.ratio.value = 12;
                compressor.reduction.value = -20;
                compressor.attack.value = 0;
                compressor.release.value = 0.25;

                filter.connect(compressor);

                return [filter, compressor];
            };

            const micStream = await navigator.mediaDevices.getUserMedia({
                audio: {sampleRate: 16000, noiseSuppression: true, autoGainControl: false},
                video: false
            });

            const context = new AudioContext({sampleRate: sampleRate});
            const source = context.createMediaStreamSource(micStream);
            const gain = context.createGain();
            const processor = context.createScriptProcessor(1024, 1, 1);
            processor.onaudioprocess = e => samples.push(e.inputBuffer.getChannelData(0));
            const filters = createFilters(context);

            window.context = context;
            window.micStream = micStream;

            const useFilters = false
            if (useFilters) {
                source.connect(gain);
                gain.connect(filters[0]);
                filters[filters.length - 1].connect(processor);
                filters[filters.length - 1].connect(context.destination);
                processor.connect(context.destination);
            } else {
                source.connect(gain);
                gain.connect(context.destination);
                gain.connect(processor);
                processor.connect(context.destination);
            }

            samples.on('data', () => drawWaveform());

            samples.on('full', async data => {
                await stopRecording();
                const predictionExt = {};

                window.waveform = data;
                window.predictionExt = predictionExt;

                predictionExt['en'] = await wav2letter.predictExt({waveform: data, lang: 'en'});
                addLettersForPredictionExt(predictionExt['en']);
                predictionExt['de'] = await wav2letter.predictExt({waveform: data, lang: 'de'});
                addLettersForPredictionExt(predictionExt['de']);

                drawSpectrogram(predictionExt['en'].logMelSpectrogram);

            });

            async function startRecording() {
                document.getElementById("record-button").style.color = 'red';
                samples.clear();
                document.getElementById("spectrogram-viz").getContext("2d").clearRect(0, 0, canvas.width, canvas.height);
                ["en", "de"].forEach(l => setTranscriptionText("", l));
                await unmuteRecording();
            }

            async function stopRecording() {
                document.getElementById("record-button").style.color = "inherit";
                await muteRecording();
            }

            async function muteRecording() {
                gain.gain.value = 0.0;
            }

            async function unmuteRecording() {
                gain.gain.value = 1.0;
            }

            await stopRecording();

            const canvas = document.querySelector('#waveform-viz');
            const canvasCtx = canvas.getContext("2d");

            function drawWaveform() {
                const amplification = 1.0 / samples.data.reduce((max, cur) => Math.max(max, Math.abs(cur)), 0.1);

                canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

                canvasCtx.save();
                canvasCtx.imageSmoothingEnabled = false;
                canvasCtx.translate(0, canvas.height / 2.0);
                canvasCtx.strokeStyle = '#999';
                canvasCtx.fillStyle = '#000';
                canvasCtx.beginPath();
                canvasCtx.moveTo(0, 0);
                canvasCtx.lineTo(canvas.width * samples.length, 0.0);
                canvasCtx.stroke();
                canvasCtx.strokeStyle = '#000';
                canvasCtx.beginPath();
                canvasCtx.moveTo(0, 0);
                const samplesSoFar = samples.data;
                for (let i = 0; i < samplesSoFar.length; ++i)
                    canvasCtx.lineTo(i / samples.maxLength * canvas.width, +0.5 * amplification * samplesSoFar[i] * canvas.height);
                for (let i = samplesSoFar.length - 1; i >= 0; --i)
                    canvasCtx.lineTo(i / samples.maxLength * canvas.width, -0.5 * amplification * samplesSoFar[i] * canvas.height);
                canvasCtx.closePath();
                canvasCtx.fill();
                canvasCtx.stroke();
                canvasCtx.restore();
            }

            drawWaveform();

            return {
                startRecording: startRecording,
                stopRecording: stopRecording,
                muteRecording: muteRecording,
            };
        }
    </script>
</head>
<body>
<div id="main">
    <div id="waveform">
        <canvas id="waveform-viz" width="512" height="128"></canvas>
        <br/>
        <canvas id="spectrogram-viz" width="512" height="128"></canvas>
    </div>
    <br>
    <br>
    <div id="mic" onmousedown="state.startRecording();">
        <br>
        <i id="record-button"
           class="fas fa-microphone">
        </i>
    </div>
    <div class="transcription-wrapper">
        English
        <div id="chunks-en" class="transcription"></div>
    </div>
    <div class="transcription-wrapper">
        German
        <div id="chunks-de" class="transcription"></div>
    </div>
</div>
<script>
    let state;
    init().then(s => state = s);
</script>
</body>
</html>
